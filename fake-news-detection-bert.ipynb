{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9785358,"sourceType":"datasetVersion","datasetId":5995387}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install necessary libraries\n!pip install transformers\n!pip install tqdm\n\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom tqdm.auto import tqdm\n\n# Check if GPU is available\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-02T07:21:03.551735Z","iopub.execute_input":"2024-11-02T07:21:03.552596Z","iopub.status.idle":"2024-11-02T07:21:33.752889Z","shell.execute_reply.started":"2024-11-02T07:21:03.552554Z","shell.execute_reply":"2024-11-02T07:21:33.751769Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the dataset from the provided path\ndf = pd.read_csv('/kaggle/input/bert-fake-news-detection/News_Data.csv')\n\n# Verify the data\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:21:33.755136Z","iopub.execute_input":"2024-11-02T07:21:33.755817Z","iopub.status.idle":"2024-11-02T07:21:36.001764Z","shell.execute_reply.started":"2024-11-02T07:21:33.755774Z","shell.execute_reply":"2024-11-02T07:21:36.000854Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0   BREAKING: GOP Chairman Grassley Has Had Enoug...   \n1   Failed GOP Candidates Remembered In Hilarious...   \n2   Mike Pence’s New DC Neighbors Are HILARIOUSLY...   \n3  California AG pledges to defend birth control ...   \n4  AZ RANCHERS Living On US-Mexico Border Destroy...   \n\n                                                text       subject       date  \\\n0  Donald Trump s White House is in chaos and the...          News  21-Jul-17   \n1  Now that Donald Trump is the presumptive GOP n...          News   7-May-16   \n2  Mike Pence is a huge homophobe He supports exg...          News   3-Dec-16   \n3  SAN FRANCISCO Reuters  California Attorney Gen...  politicsNews   6-Oct-17   \n4  Twisted reasoning is all that comes from Pelos...      politics  25-Apr-17   \n\n   label  \n0    0.0  \n1    0.0  \n2    0.0  \n3    1.0  \n4    0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BREAKING: GOP Chairman Grassley Has Had Enoug...</td>\n      <td>Donald Trump s White House is in chaos and the...</td>\n      <td>News</td>\n      <td>21-Jul-17</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Failed GOP Candidates Remembered In Hilarious...</td>\n      <td>Now that Donald Trump is the presumptive GOP n...</td>\n      <td>News</td>\n      <td>7-May-16</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mike Pence’s New DC Neighbors Are HILARIOUSLY...</td>\n      <td>Mike Pence is a huge homophobe He supports exg...</td>\n      <td>News</td>\n      <td>3-Dec-16</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>California AG pledges to defend birth control ...</td>\n      <td>SAN FRANCISCO Reuters  California Attorney Gen...</td>\n      <td>politicsNews</td>\n      <td>6-Oct-17</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AZ RANCHERS Living On US-Mexico Border Destroy...</td>\n      <td>Twisted reasoning is all that comes from Pelos...</td>\n      <td>politics</td>\n      <td>25-Apr-17</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check the counts of each label\nlabel_counts = df['label'].value_counts()\nprint(label_counts)\n\nprint(f\"Number of True news articles: {label_counts.get(1, 0)}\")\nprint(f\"Number of False news articles: {label_counts.get(0, 0)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:21:39.872125Z","iopub.execute_input":"2024-11-02T07:21:39.872886Z","iopub.status.idle":"2024-11-02T07:21:39.887561Z","shell.execute_reply.started":"2024-11-02T07:21:39.872844Z","shell.execute_reply":"2024-11-02T07:21:39.886649Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"label\n0.0    23463\n1.0    21417\nName: count, dtype: int64\nNumber of True news articles: 21417\nNumber of False news articles: 23463\n","output_type":"stream"}]},{"cell_type":"code","source":"# Combine 'title' and 'text' into one column (if necessary)\ndf['content'] = df['title'] + ' ' + df['text']\n\n# Drop rows with missing values\ndf.dropna(subset=['content', 'label'], inplace=True)\n\n# Ensure labels are integers\ndf['label'] = df['label'].astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:21:43.492199Z","iopub.execute_input":"2024-11-02T07:21:43.492810Z","iopub.status.idle":"2024-11-02T07:21:43.664903Z","shell.execute_reply.started":"2024-11-02T07:21:43.492773Z","shell.execute_reply":"2024-11-02T07:21:43.664107Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and validation sets\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['content'].tolist(),\n    df['label'].tolist(),\n    test_size=0.2,\n    random_state=42,\n    stratify=df['label']  # Maintain label proportions\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:21:47.384468Z","iopub.execute_input":"2024-11-02T07:21:47.384821Z","iopub.status.idle":"2024-11-02T07:21:47.432656Z","shell.execute_reply.started":"2024-11-02T07:21:47.384790Z","shell.execute_reply":"2024-11-02T07:21:47.431925Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Initialize the BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Create a custom dataset class\nclass FakeNewsDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.encodings = tokenizer(\n            texts,\n            add_special_tokens=True,\n            max_length=256,  # Adjusted max_length to reduce memory usage\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# Create datasets\ntrain_dataset = FakeNewsDataset(train_texts, train_labels)\nval_dataset = FakeNewsDataset(val_texts, val_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:21:54.201672Z","iopub.execute_input":"2024-11-02T07:21:54.202435Z","iopub.status.idle":"2024-11-02T07:33:45.389705Z","shell.execute_reply.started":"2024-11-02T07:21:54.202394Z","shell.execute_reply":"2024-11-02T07:33:45.388797Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc41f3893e24417ba14f3c2774f7576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc10ae026a74129a27ab3c432c615c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44dccb95db3c406694d30234bd344397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b9b20d2d411411a834f06353016cd66"}},"metadata":{}}]},{"cell_type":"code","source":"# Adjusted batch size\nbatch_size = 32  # Adjust based on GPU memory\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:37:35.792315Z","iopub.execute_input":"2024-11-02T07:37:35.792674Z","iopub.status.idle":"2024-11-02T07:37:35.797727Z","shell.execute_reply.started":"2024-11-02T07:37:35.792642Z","shell.execute_reply":"2024-11-02T07:37:35.796797Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Load the pre-trained BERT model for sequence classification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:37:41.051938Z","iopub.execute_input":"2024-11-02T07:37:41.052338Z","iopub.status.idle":"2024-11-02T07:37:41.477222Z","shell.execute_reply.started":"2024-11-02T07:37:41.052300Z","shell.execute_reply":"2024-11-02T07:37:41.476235Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define optimizer and scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\nepochs = 5  # Adjust as necessary\ntotal_steps = len(train_loader) * epochs\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:37:45.734564Z","iopub.execute_input":"2024-11-02T07:37:45.734940Z","iopub.status.idle":"2024-11-02T07:37:45.744475Z","shell.execute_reply.started":"2024-11-02T07:37:45.734905Z","shell.execute_reply":"2024-11-02T07:37:45.743554Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Loss function\ncriterion = torch.nn.CrossEntropyLoss()\n\n# Training loop\nfor epoch in range(epochs):\n    print(f'\\n======== Epoch {epoch + 1} / {epochs} ========')\n    print('Training...')\n    \n    model.train()\n    total_train_loss = 0\n    total_train_accuracy = 0\n    train_steps = 0\n\n    for batch in tqdm(train_loader, desc='Training', leave=False):\n        optimizer.zero_grad()\n\n        # Move batch to device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Forward pass\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels  # Including labels here allows automatic loss computation\n        )\n\n        loss = outputs.loss\n        logits = outputs.logits\n\n        total_train_loss += loss.item()\n\n        # Backward pass\n        loss.backward()\n\n        # Gradient clipping\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # Update optimizer and scheduler\n        optimizer.step()\n        scheduler.step()\n\n        # Calculate accuracy\n        preds = torch.argmax(logits, dim=1)\n        batch_accuracy = (preds == labels).cpu().numpy().mean()\n        total_train_accuracy += batch_accuracy\n        train_steps += 1\n\n    avg_train_loss = total_train_loss / train_steps\n    avg_train_accuracy = total_train_accuracy / train_steps\n\n    print(f\"Training Loss: {avg_train_loss:.4f}\")\n    print(f\"Training Accuracy: {avg_train_accuracy:.4f}\")\n\n    # Validation\n    print('\\nRunning Validation...')\n    model.eval()\n    total_val_loss = 0\n    total_val_accuracy = 0\n    val_steps = 0\n\n    for batch in tqdm(val_loader, desc='Validation', leave=False):\n        with torch.no_grad():\n            # Move batch to device\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            # Forward pass\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n\n            loss = outputs.loss\n            logits = outputs.logits\n\n        total_val_loss += loss.item()\n\n        # Calculate accuracy\n        preds = torch.argmax(logits, dim=1)\n        batch_accuracy = (preds == labels).cpu().numpy().mean()\n        total_val_accuracy += batch_accuracy\n        val_steps += 1\n\n    avg_val_loss = total_val_loss / val_steps\n    avg_val_accuracy = total_val_accuracy / val_steps\n\n    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n    print(f\"Validation Accuracy: {avg_val_accuracy:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T07:37:52.268746Z","iopub.execute_input":"2024-11-02T07:37:52.269139Z","iopub.status.idle":"2024-11-02T08:52:58.947521Z","shell.execute_reply.started":"2024-11-02T07:37:52.269102Z","shell.execute_reply":"2024-11-02T08:52:58.946509Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\n======== Epoch 1 / 5 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1120 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0160\nTraining Accuracy: 0.9950\n\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/280 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Loss: 0.0031\nValidation Accuracy: 0.9996\n\n======== Epoch 2 / 5 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1120 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0013\nTraining Accuracy: 0.9997\n\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/280 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Loss: 0.0029\nValidation Accuracy: 0.9997\n\n======== Epoch 3 / 5 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1120 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0005\nTraining Accuracy: 0.9999\n\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/280 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Loss: 0.0012\nValidation Accuracy: 0.9999\n\n======== Epoch 4 / 5 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1120 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0000\nTraining Accuracy: 1.0000\n\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/280 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Loss: 0.0014\nValidation Accuracy: 0.9998\n\n======== Epoch 5 / 5 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/1120 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Training Loss: 0.0000\nTraining Accuracy: 1.0000\n\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation:   0%|          | 0/280 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Loss: 0.0022\nValidation Accuracy: 0.9998\n","output_type":"stream"}]},{"cell_type":"code","source":"print('\\nEvaluating on Validation Set...')\nmodel.eval()\npredictions, true_labels = [], []\n\nfor batch in tqdm(val_loader, desc='Evaluating', leave=False):\n    with torch.no_grad():\n        # Move batch to device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        # Forward pass\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n\n        logits = outputs.logits\n\n    preds = torch.argmax(logits, dim=1)\n    predictions.extend(preds.cpu().numpy())\n    true_labels.extend(labels.cpu().numpy())\n\n# Classification report\nprint('\\nClassification Report:')\nprint(classification_report(true_labels, predictions, target_names=['Fake', 'Real']))\n\n# Confusion matrix\nprint('\\nConfusion Matrix:')\nprint(confusion_matrix(true_labels, predictions))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T08:52:58.949708Z","iopub.execute_input":"2024-11-02T08:52:58.950123Z","iopub.status.idle":"2024-11-02T08:54:03.037265Z","shell.execute_reply.started":"2024-11-02T08:52:58.950059Z","shell.execute_reply":"2024-11-02T08:54:03.036265Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nEvaluating on Validation Set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/280 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n        Fake       1.00      1.00      1.00      4676\n        Real       1.00      1.00      1.00      4284\n\n    accuracy                           1.00      8960\n   macro avg       1.00      1.00      1.00      8960\nweighted avg       1.00      1.00      1.00      8960\n\n\nConfusion Matrix:\n[[4675    1]\n [   1 4283]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the trained model and tokenizer\nmodel.save_pretrained('/kaggle/working/fake-news-bert-model')\ntokenizer.save_pretrained('/kaggle/working/fake-news-bert-tokenizer')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T08:54:03.038409Z","iopub.execute_input":"2024-11-02T08:54:03.038796Z","iopub.status.idle":"2024-11-02T08:54:04.057371Z","shell.execute_reply.started":"2024-11-02T08:54:03.038752Z","shell.execute_reply":"2024-11-02T08:54:04.056431Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/fake-news-bert-tokenizer/tokenizer_config.json',\n '/kaggle/working/fake-news-bert-tokenizer/special_tokens_map.json',\n '/kaggle/working/fake-news-bert-tokenizer/vocab.txt',\n '/kaggle/working/fake-news-bert-tokenizer/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r /kaggle/working/Tokenizer.zip /kaggle/working/fake-news-bert-tokenizer/*\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:09:19.788752Z","iopub.execute_input":"2024-11-02T09:09:19.789201Z","iopub.status.idle":"2024-11-02T09:09:20.858372Z","shell.execute_reply.started":"2024-11-02T09:09:19.789160Z","shell.execute_reply":"2024-11-02T09:09:20.857250Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"updating: kaggle/working/fake-news-bert-tokenizer/special_tokens_map.json (deflated 42%)\nupdating: kaggle/working/fake-news-bert-tokenizer/vocab.txt (deflated 53%)\nupdating: kaggle/working/fake-news-bert-tokenizer/tokenizer_config.json (deflated 75%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r /kaggle/working/model.zip /kaggle/working/fake-news-bert-model/*\n","metadata":{"execution":{"iopub.status.busy":"2024-11-02T09:10:33.067723Z","iopub.execute_input":"2024-11-02T09:10:33.068575Z","iopub.status.idle":"2024-11-02T09:10:56.742028Z","shell.execute_reply.started":"2024-11-02T09:10:33.068530Z","shell.execute_reply":"2024-11-02T09:10:56.740885Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/fake-news-bert-model/config.json (deflated 49%)\n  adding: kaggle/working/fake-news-bert-model/model.safetensors (deflated 7%)\n","output_type":"stream"}]}]}